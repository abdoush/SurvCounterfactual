{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.dataset import FlchainSub1, PM\n",
    "import numpy as np\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "import pickle\n",
    "from model import SurvCounterfactual\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyswarms.utils.plotters import (plot_cost_history, plot_contour, plot_surface)\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import shap\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6a2ea",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0582451",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'PM_Example'\n",
    "os.makedirs(f'Results/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PM('Dataset/PM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70009324",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, ye_train, y_train, e_train,\n",
    " x_val, ye_val, y_val, e_val,\n",
    " x_test, ye_test, y_test, e_test) = ds.get_train_val_test_from_splits(test_id=0, val_id=1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_time_data(subset):\n",
    "    T = subset[2]\n",
    "    E = subset[3]\n",
    "    dtypes = np.dtype('bool,float')\n",
    "    ET = np.array([(bool(e), t) for e, t in zip(E, T)], dtype=dtypes)\n",
    "    \n",
    "    return ET\n",
    "\n",
    "def get_idx_data(subset):\n",
    "    return subset[0]\n",
    "\n",
    "def get_features_data(subset):\n",
    "    return subset[1]\n",
    "\n",
    "def get_time_data(subset):\n",
    "    return subset[2]\n",
    "\n",
    "def get_event_data(subset):\n",
    "    return subset[3]\n",
    "\n",
    "def plot_pca_time(x, pca_mdl, labels, col_names=None, suffix='a', label='Data', size=30):\n",
    "    if pca_mdl is None:\n",
    "        x_pca = x\n",
    "    else:\n",
    "        x_pca = pca_mdl.transform(x)\n",
    "    \n",
    "    if col_names is None:\n",
    "        col_names = ['PC0', 'PC1', 'PC2']\n",
    "    \n",
    "    if x_pca.shape[1] == 2:\n",
    "        k = 1\n",
    "    else:\n",
    "        k=3\n",
    "        \n",
    "    fig, ax = plt.subplots(1,k, figsize=(7*k, 5))\n",
    "    \n",
    "    plt.title(\"Data distribution (PCA)\")\n",
    "    if k == 1:\n",
    "        im0= ax.scatter(x_pca[:, 0], x_pca[:, 1], c=labels, alpha=1, cmap='viridis', s=size, label=label)\n",
    "        ax.set_xlabel(col_names[0])\n",
    "        ax.set_ylabel(col_names[1])\n",
    "        fig.colorbar(im0, ax=ax, orientation='vertical')\n",
    "    else:\n",
    "        im0= ax[0].scatter(x_pca[:, 0], x_pca[:, 1], c=labels, alpha=1, cmap='viridis', s=size, label=label)\n",
    "        ax[0].set_xlabel(col_names[0])\n",
    "        ax[0].set_ylabel(col_names[1])\n",
    "        fig.colorbar(im0, ax=ax[0], orientation='vertical')\n",
    "\n",
    "        im1= ax[1].scatter(x_pca[:, 0], x_pca[:, 2], c=labels, alpha=1, cmap='viridis', s=size, label=label)\n",
    "        ax[1].set_xlabel(col_names[0])\n",
    "        ax[1].set_ylabel(col_names[2])\n",
    "        fig.colorbar(im1, ax=ax[1], orientation='vertical')\n",
    "\n",
    "\n",
    "        im2=ax[2].scatter(x_pca[:, 1], x_pca[:, 2], c=labels, alpha=1, cmap='viridis', s=size, label=label)\n",
    "        ax[2].set_xlabel(col_names[1])\n",
    "        ax[2].set_ylabel(col_names[2])\n",
    "        fig.colorbar(im2, ax=ax[2], orientation='vertical')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Results/{exp_name}/scatter_time_{suffix}.pdf', format='pdf', bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "def plot_pca_time_3D(x, pca_mdl, labels, col_names=None, suffix='a', label='Data', size=30):\n",
    "    if pca_mdl is None:\n",
    "        x_pca = x\n",
    "    else:\n",
    "        x_pca = pca_mdl.transform(x)\n",
    "        \n",
    "    if col_names is None:\n",
    "        col_names = ['PC0', 'PC1', 'PC2']\n",
    "    \n",
    "    if x_pca.shape[1] <3:\n",
    "        print('Data is less than 3D')\n",
    "        return\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(x_pca[:, 0], x_pca[:, 1], x_pca[:, 2], c=labels, alpha=1, cmap='viridis', s=size, label=label)\n",
    "    ax.view_init(elev=30., azim=-60)\n",
    "    #ax.view_init(elev=10., azim=30)\n",
    "    ax.set_xlabel(col_names[0])\n",
    "    ax.set_ylabel(col_names[1])\n",
    "    ax.set_zlabel(col_names[2])\n",
    "    plt.savefig(f'Results/{exp_name}/scatter_time_3D_{suffix}.pdf', format='pdf', bbox_inches='tight')\n",
    "    \n",
    "def plot_pca_patterns(x, labels, pca_mdl, col_names=None, x_origs=None, x_cfacts=None, suffix='a', size=30, csize=60, alpha=0.5):\n",
    "    if pca_mdl is None:\n",
    "        x_pca = x\n",
    "        if x_origs is not None:\n",
    "            x_pca_origs = x_origs\n",
    "        if x_cfacts is not None:\n",
    "            x_pca_cfacts = x_cfacts\n",
    "    else:\n",
    "        x_pca = pca_mdl.transform(x)\n",
    "        if x_origs is not None:\n",
    "            x_pca_origs = pca_mdl.transform(x_origs)\n",
    "        if x_cfacts is not None:\n",
    "            x_pca_cfacts = pca_mdl.transform(x_cfacts)\n",
    "        \n",
    "    if col_names is None:\n",
    "        col_names = ['PC0', 'PC1', 'PC2']\n",
    "        \n",
    "    \n",
    "    if x_pca.shape[1] == 2:\n",
    "        k = 1\n",
    "    else:\n",
    "        k=3\n",
    "    fig, ax = plt.subplots(1,k, figsize=(7*k, 5))\n",
    "    plt.title(\"Data distribution (PCA)\")\n",
    "    for p in set(labels):\n",
    "        if k == 1:\n",
    "            ax.scatter(x_pca[labels==p, 0], x_pca[labels==p, 1], c=f'C{p}', alpha=alpha, s=size, label=f\"Pattern {p}\")\n",
    "            ax.set_xlabel(col_names[0])\n",
    "            ax.set_ylabel(col_names[1])\n",
    "        else:\n",
    "            ax[0].scatter(x_pca[labels==p, 0], x_pca[labels==p, 1], c=f'C{p}', alpha=alpha, s=size, label=f\"Pattern {p}\")\n",
    "            ax[0].set_xlabel(col_names[0])\n",
    "            ax[0].set_ylabel(col_names[1])\n",
    "\n",
    "            ax[1].scatter(x_pca[labels==p, 0], x_pca[labels==p, 2], c=f'C{p}', alpha=alpha, s=size, label=f\"Pattern {p}\")\n",
    "            ax[1].set_xlabel(col_names[0])\n",
    "            ax[1].set_ylabel(col_names[2])\n",
    "\n",
    "            ax[2].scatter(x_pca[labels==p, 1], x_pca[labels==p, 2], c=f'C{p}', alpha=alpha, s=size, label=f\"Pattern {p}\")\n",
    "            ax[2].set_xlabel(col_names[1])\n",
    "            ax[2].set_ylabel(col_names[2])\n",
    "        \n",
    "    if x_origs is not None:\n",
    "        if k == 1:\n",
    "            ax.scatter(x_pca_origs[:, 0], x_pca_origs[:, 1], c='k', alpha=1, s=csize, marker='*', label=\"Originals\")\n",
    "        else:\n",
    "            ax[0].scatter(x_pca_origs[:, 0], x_pca_origs[:, 1], c='k', alpha=1, s=csize, marker='*', label=\"Originals\")\n",
    "            ax[1].scatter(x_pca_origs[:, 0], x_pca_origs[:, 2], c='k', alpha=1, s=csize, marker='*', label=\"Originals\")\n",
    "            ax[2].scatter(x_pca_origs[:, 1], x_pca_origs[:, 2], c='k', alpha=1, s=csize, marker='*', label=\"Originals\")\n",
    "    if x_cfacts is not None:\n",
    "        if k == 1:\n",
    "            ax.scatter(x_pca_cfacts[:, 0], x_pca_cfacts[:, 1], c='k', alpha=1, s=csize, marker='^', label=\"Originals\")\n",
    "        else:\n",
    "            ax[0].scatter(x_pca_cfacts[:, 0], x_pca_cfacts[:, 1], c='k', alpha=1, s=csize, marker='^', label=\"Originals\")\n",
    "            ax[1].scatter(x_pca_cfacts[:, 0], x_pca_cfacts[:, 2], c='k', alpha=1, s=csize, marker='^', label=\"Originals\")\n",
    "            ax[2].scatter(x_pca_cfacts[:, 1], x_pca_cfacts[:, 2], c='k', alpha=1, s=csize, marker='^', label=\"Counterfacts\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Results/{exp_name}/scatter_patterns_{suffix}.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "def plot_pca_patterns_3D(x, labels, pca_mdl, col_names=None, x_origs=None, x_cfacts=None, x_cfacts1=None, suffix='a', size=30, csize=60, alpha=0.5, ax=None):\n",
    "    if pca_mdl is None:\n",
    "        x_pca = x\n",
    "        if x_origs is not None:\n",
    "            x_pca_origs = x_origs\n",
    "        if x_cfacts is not None:\n",
    "            x_pca_cfacts = x_cfacts\n",
    "        if x_cfacts1 is not None:\n",
    "            x_pca_cfacts1 = x_cfacts1\n",
    "    else:\n",
    "        x_pca = pca_mdl.transform(x)\n",
    "        if x_origs is not None:\n",
    "            x_pca_origs = pca_mdl.transform(x_origs)\n",
    "        if x_cfacts is not None:\n",
    "            x_pca_cfacts = pca_mdl.transform(x_cfacts)\n",
    "        if x_cfacts1 is not None:\n",
    "            x_pca_cfacts1 = pca_mdl.transform(x_cfacts1)\n",
    "        \n",
    "    if col_names is None:\n",
    "        col_names = ['PC0', 'PC1', 'PC2']\n",
    "    \n",
    "    if x_pca.shape[1] <3:\n",
    "        print('Data is less than 3D')\n",
    "        return\n",
    "    \n",
    "    if ax==None:\n",
    "        fig = plt.figure(figsize=(5, 5))\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "    for p in set(explainer.labels_train):\n",
    "        ax.scatter(X_pca_train[explainer.labels_train==p, 0], X_pca_train[explainer.labels_train==p, 1], X_pca_train[explainer.labels_train==p, 2], c=f'C{p}', alpha=alpha, s=size, label=f\"Pattern {p}\")\n",
    "    \n",
    "    if x_origs is not None:\n",
    "        ax.scatter(x_pca_origs[:, 0], x_pca_origs[:, 1], x_pca_origs[:, 2], c='k', alpha=1, s=csize, marker='x', label=\"Original Points\")\n",
    "    if x_cfacts is not None:\n",
    "        ax.scatter(x_pca_cfacts[:, 0], x_pca_cfacts[:, 1], x_pca_cfacts[:, 2], marker='^', facecolors='limegreen', edgecolors='w', alpha=1, s=csize*2, label=\"Counterfactuals w/o AE\")\n",
    "    if x_cfacts1 is not None:\n",
    "        ax.scatter(x_pca_cfacts1[:, 0], x_pca_cfacts1[:, 1], x_pca_cfacts1[:, 2], marker='s', facecolors='dodgerblue', edgecolors='w', alpha=1, s=csize, label=\"Counterfactuals w AE\")\n",
    "    \n",
    "    ax.view_init(elev=30., azim=-60)\n",
    "    ax.set_xlabel(col_names[0])\n",
    "    ax.set_ylabel(col_names[1])\n",
    "    ax.set_zlabel(col_names[2])\n",
    "    leg = plt.legend(loc=(1.15, 0.3))\n",
    "    for lh in leg.legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "    plt.locator_params(axis='both', nbins=4)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.savefig(f'Results/{exp_name}/scatter_patterns_3D_{suffix}.pdf', format='pdf', bbox_inches='tight')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def find_counterfactuals(x, targets, explainer, \n",
    "                         feature_names,\n",
    "                         feature_types=None,\n",
    "                         ohe_features=None,\n",
    "                         mask=None, \n",
    "                         norm=1, \n",
    "                         anomaly_model=None,\n",
    "                         anomaly_threshold=0,\n",
    "                         n_particles=500, n_iterations=100000, patience=1000, \n",
    "                         loss_distance_weight=1,\n",
    "                         loss_anomaly_weight=1, \n",
    "                         loss_target_weight=1e5, \n",
    "                         loss_mutual_exclusions_weight=1e5):\n",
    "    x_cfacts = []\n",
    "    p_preds = []\n",
    "    hists = []\n",
    "    for (x_sample, p_target) in zip(x, targets):\n",
    "        x_cfact = explainer.explain(x=x_sample,\n",
    "                                    target_pattern=p_target, \n",
    "                                    features_names_list=feature_names,\n",
    "                                    feature_types = feature_types,\n",
    "                                    ohe_features=ohe_features,\n",
    "                                    mask= mask,\n",
    "                                    norm=norm,\n",
    "                                    anomaly_model=anomaly_model,\n",
    "                                    anomaly_threshold=anomaly_threshold,\n",
    "                                    n_particles=n_particles,\n",
    "                                    n_iterations=n_iterations,\n",
    "                                    patience=patience,\n",
    "                                    loss_distance_weight=loss_distance_weight,\n",
    "                                    loss_anomaly_weight=loss_anomaly_weight,\n",
    "                                    loss_target_weight=loss_target_weight, \n",
    "                                    loss_mutual_exclusions_weight=loss_mutual_exclusions_weight\n",
    "                                   )\n",
    "        p_pred = explainer.predict(x_cfact[np.newaxis])\n",
    "\n",
    "        p_preds.append(p_pred)\n",
    "        x_cfacts.append(x_cfact)\n",
    "        hists.append(explainer.optimizer.history)\n",
    "    \n",
    "    return np.array(x_cfacts), np.array(p_preds), hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(x_train)\n",
    "X_pca_train = pca.transform(x_train)\n",
    "print('PCA explained variance: {:.2f} %'.format(pca.explained_variance_ratio_.sum()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_time(x_train, pca_mdl=pca, col_names=None, suffix='a', labels=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07680428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_time_3D(x_train, pca_mdl=pca, col_names=None, suffix='a', labels=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aea565",
   "metadata": {},
   "source": [
    "# Train Survival Model (Random Survival Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8902041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# special for RSF\n",
    "dt = np.dtype('bool,float')\n",
    "y_train_surv = np.array([(bool(e), y) for e, y in zip(e_train, y_train)], dtype=dt)\n",
    "y_val_surv = np.array([(bool(e), y) for e, y in zip(e_val, y_val)], dtype=dt)\n",
    "y_test_surv = np.array([(bool(e), y) for e, y in zip(e_test, y_test)], dtype=dt)\n",
    "print(y_train_surv.shape)\n",
    "\n",
    "# train RSF\n",
    "rsf = RandomSurvivalForest(n_estimators=15,\n",
    "                           min_samples_split=20,\n",
    "                           min_samples_leaf=10,\n",
    "                           max_features=\"sqrt\",\n",
    "                           oob_score=True,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=20)\n",
    "rsf.fit(x_train, y_train_surv)\n",
    "\n",
    "cindex_train = rsf.score(x_train, y_train_surv)\n",
    "cindex_oob = rsf.oob_score_\n",
    "cindex_val = rsf.score(x_val, y_val_surv)\n",
    "cindex_test = rsf.score(x_test, y_test_surv)\n",
    "\n",
    "print('Train cindex {:.2f}'.format(cindex_train*100))\n",
    "print('Val cindex {:.2f}'.format(cindex_val*100))\n",
    "print('Test cindex {:.2f}'.format(cindex_test*100))\n",
    "print('oob cindex {:.2f}'.format(cindex_oob*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f1350",
   "metadata": {},
   "source": [
    "# Prepare the Data and the Survival Curves for SurvCounterFactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_train = rsf.predict_survival_function(x_train, return_array=True)\n",
    "surv_val = rsf.predict_survival_function(x_val, return_array=True)\n",
    "surv_test = rsf.predict_survival_function(x_test, return_array=True)\n",
    "\n",
    "event_times=rsf.event_times_\n",
    "\n",
    "#Prepare Data for Explanation\n",
    "xte_data = (x_train, y_train, e_train,\n",
    "            x_val, y_val, e_val,\n",
    "            x_test, y_test, e_test)\n",
    "\n",
    "#Prepare the Survival Curves for Explanation\n",
    "survival_curves = (surv_train, surv_val, surv_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaa132",
   "metadata": {},
   "source": [
    "# Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c3bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = SurvCounterfactual(prefix_name=exp_name, max_depth=5)\n",
    "explainer.fit(xte_data=xte_data, survival_curves=survival_curves, event_times=event_times, survival_mdl=rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_patterns(x_train, explainer.labels_train, pca_mdl=pca, suffix='patterns', col_names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d76938",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_patterns_3D(x_train, explainer.labels_train, pca_mdl=pca, suffix='patterns', col_names=None, alpha=0.01, size=200, csize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = ['float', 'float', 'float', 'bool', 'bool', 'bool', 'bool', 'bool', 'bool', 'bool']\n",
    "\n",
    "ohe_features = [[3, 4, 5], [6, 7, 8, 9]]\n",
    "\n",
    "mask = [1]*x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a3426",
   "metadata": {},
   "source": [
    "# Without Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_source = 7\n",
    "y_target = 4\n",
    "n_samples = 2#x_train[explainer.labels_train==y_source].shape[0]\n",
    "x_sources = x_train[explainer.labels_train==y_source][:n_samples].copy()\n",
    "y_targets = np.array([y_target]*n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432248f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_cfacts, p_preds, hists =find_counterfactuals(x=x_sources,\n",
    "                                        targets=y_targets, \n",
    "                                        explainer=explainer, \n",
    "                                        feature_names=ds.feature_names,\n",
    "                                        feature_types=feature_types,\n",
    "                                        ohe_features=ohe_features,\n",
    "                                        mask=mask, \n",
    "                                        norm=1, \n",
    "                                        anomaly_model=None, \n",
    "                                        n_particles=100, n_iterations=100000, patience=200, \n",
    "                                        loss_distance_weight=1,\n",
    "                                        loss_anomaly_weight=1, \n",
    "                                        loss_target_weight=1e2, \n",
    "                                        loss_mutual_exclusions_weight=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041957ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,fs in enumerate(ohe_features):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(9, 2))\n",
    "    ax[0].bar(np.array(ds.feature_names)[fs], x_sources[:,fs].sum(axis=0))\n",
    "    ax[0].set_xticklabels(np.array(ds.feature_names)[fs], rotation=45)\n",
    "    ax[0].set_title(f'Source Pattern {y_source}')\n",
    "    ax[0].yaxis.set_major_formatter(FormatStrFormatter('%.d'))\n",
    "    ax[1].bar(np.array(ds.feature_names)[fs], x_cfacts[:,fs].sum(axis=0))\n",
    "    ax[1].set_xticklabels(np.array(ds.feature_names)[fs], rotation=45)\n",
    "    ax[1].set_title(f'CounterFactual Target Pattern {y_target}')\n",
    "    ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.d'))\n",
    "    ax[2].bar(np.array(ds.feature_names)[fs], x_train[explainer.labels_train==y_target][:,fs].sum(axis=0))\n",
    "    ax[2].set_xticklabels(np.array(ds.feature_names)[fs], rotation=45)\n",
    "    ax[2].set_title(f'Data Target Pattern {y_target}')\n",
    "    ax[2].yaxis.set_major_formatter(FormatStrFormatter('%.d'))\n",
    "    plt.savefig(f'Results/{exp_name}/OHE_source_target_cfacts_distributions_{i}_no_AE.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5178a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_patterns(x_train, explainer.labels_train, pca_mdl=pca, col_names=None, suffix='no_AE', x_origs=x_sources, x_cfacts=x_cfacts,size=50, csize=50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plot_pca_patterns_3D(x_train, explainer.labels_train, pca_mdl=pca, col_names=None, suffix='no_AE', x_origs=x_sources, x_cfacts=x_cfacts,size=200, csize=100, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd655ab2",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import Autoencoder, AutoencoderDataset, AutoencoderLearner\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "train_loader = AutoencoderDataset(x_train)\n",
    "val_loader = AutoencoderDataset(x_val)\n",
    "\n",
    "autoencoder = Autoencoder(n_features=x_train.shape[-1],\n",
    "                         hidden_layers_size=[16, 16],\n",
    "                         latent_size=4,\n",
    "                         activation=\"relu\",\n",
    "                         last_activation=\"sigmoid\")\n",
    "\n",
    "# optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "# loss_function = MSELoss()\n",
    "\n",
    "# train_loss_list, valid_loss_list = AutoencoderLearner.run_training(autoencoder, optimizer, loss_function, \n",
    "#                                                                    train_loader, val_loader, epochs=1000,\n",
    "#                                                                    early_stopping=True,\n",
    "#                                                                    early_stopping_patience=50,\n",
    "#                                                                    early_stopping_delta=1e-5,\n",
    "#                                                                   )\n",
    "\n",
    "# autoencoder.save_weights('Flchain_autoencoder.mdl')\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "# plt.plot(valid_loss_list, label=\"Test Loss\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e40c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('PM_New_autoencoder.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af509c3f",
   "metadata": {},
   "source": [
    "# Autoencoder error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_error = autoencoder.anomaly_score_multi(x_train)\n",
    "x_val_error = autoencoder.anomaly_score_multi(x_val)\n",
    "x_test_error = autoencoder.anomaly_score_multi(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([x_train_error, x_val_error, x_test_error]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_threshold = np.quantile(x_test_error, 0.75) + 1.5*(np.quantile(x_test_error, 0.75) - np.quantile(x_test_error, 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39c949",
   "metadata": {},
   "source": [
    "# With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49587cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_cfacts1, p_preds1, hist1 =find_counterfactuals(x=x_sources,\n",
    "                                        targets=y_targets, \n",
    "                                        explainer=explainer, \n",
    "                                        feature_names=ds.feature_names,\n",
    "                                        feature_types=feature_types,\n",
    "                                        ohe_features=ohe_features,\n",
    "                                        mask=mask, \n",
    "                                        norm=1, \n",
    "                                        anomaly_model=autoencoder,\n",
    "                                        anomaly_threshold=anomaly_threshold,\n",
    "                                        n_particles=100, n_iterations=100000, patience=200, \n",
    "                                        loss_distance_weight=1,\n",
    "                                        loss_anomaly_weight=1e2, \n",
    "                                        loss_target_weight=1e2, \n",
    "                                        loss_mutual_exclusions_weight=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab258b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_patterns(x_train, explainer.labels_train, pca_mdl=pca, col_names=None, x_origs=x_sources, x_cfacts=x_cfacts1, suffix='w_AE', size=50, csize=50, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09350632",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_patterns_3D(x_train, explainer.labels_train, pca_mdl=pca, col_names=None, x_origs=x_sources, x_cfacts=x_cfacts, x_cfacts1=x_cfacts1, suffix='w_wo_AE', size=200, csize=70, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598139d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    if len(x)>1:\n",
    "        return x[1]\n",
    "    else:\n",
    "        return x[0]\n",
    "feature_names = [f1(s.split('_')) for s in ds.feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c41537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fs in enumerate(ohe_features):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 2))\n",
    "    ax[0].bar(np.array(feature_names)[fs], x_sources[:,fs].sum(axis=0))\n",
    "    ax[0].set_xticklabels(np.array(feature_names)[fs], rotation=45)\n",
    "    ax[0].set_title(f'Source Pattern {y_source}')\n",
    "    ax[1].bar(np.array(feature_names)[fs], x_train[explainer.labels_train==y_target][:,fs].sum(axis=0))\n",
    "    ax[1].set_xticklabels(np.array(feature_names)[fs], rotation=45)\n",
    "    ax[1].set_title(f'Target Pattern {y_target}')\n",
    "    ax[2].bar(np.array(feature_names)[fs], x_cfacts[:,fs].sum(axis=0))\n",
    "    ax[2].set_xticklabels(np.array(feature_names)[fs], rotation=45)\n",
    "    ax[2].set_title(f'CounterFactuals w/o AE')\n",
    "    ax[2].yaxis.set_major_formatter(FormatStrFormatter('%.d'))\n",
    "    ax[3].bar(np.array(feature_names)[fs], x_cfacts1[:,fs].sum(axis=0))\n",
    "    ax[3].set_xticklabels(np.array(feature_names)[fs], rotation=45)\n",
    "    ax[3].set_title(f'CounterFactuals w AE')\n",
    "    \n",
    "    plt.savefig(f'Results/{exp_name}/OHE_source_target_cfacts_distributions_{i}_w_wo_AE.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
